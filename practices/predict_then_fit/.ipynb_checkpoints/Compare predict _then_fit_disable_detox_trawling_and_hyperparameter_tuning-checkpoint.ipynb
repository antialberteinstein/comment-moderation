{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9e4cdb-0713-4918-acfd-b67f07744afd",
   "metadata": {},
   "source": [
    "# Compare predict then fit and normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a6446-1064-4154-8045-84f4f590f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the syspath\n",
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.abspath(os.path.join('..', '..'))\n",
    "\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb6746-52a3-488c-a2af-edeccda02fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dc07e-caa4-46e5-93a1-a045c80eb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_dataset(path):\n",
    "    dataset_path = os.path.join(root_path, *path.split('/'))\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "socc = retrieve_dataset('dataset/SOCC/processed/socc.csv')\n",
    "detox = retrieve_dataset('dataset/DETOX/processed/detox.csv')\n",
    "hasoc = retrieve_dataset('dataset/HASOC/processed/en_train.csv')\n",
    "\n",
    "# Disable because currently not support other Languages.\n",
    "# hasoc_de = retrieve_dataset('dataset/HASOC/processed/de_train.csv')\n",
    "# hasoc_hi = retrieve_dataset('dataset/HASOC/processed/hi_train.csv')\n",
    "\n",
    "trawling = retrieve_dataset('dataset/Trawling/processed/trawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8e438-d2c0-4a5a-af22-4fa8ed46e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import optuna\n",
    "from hbbrain.numerical_data.incremental_learner.iol_gfmm import ImprovedOnlineGFMM\n",
    "from preprocessing.tcw_builder import TCWBuilder\n",
    "from preprocessing.svd_extractor import SVDExtractor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21931d-d92b-47f3-b340-6ad71ac918f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    x = dataset['text']\n",
    "    labels = dataset['label']\n",
    "    y = labels.copy()\n",
    "\n",
    "    label_values = labels.unique().tolist()\n",
    "\n",
    "    for i in range(len(label_values)):\n",
    "        y[y == label_values[i]] = i\n",
    "\n",
    "    builder = TCWBuilder()\n",
    "    extractor = SVDExtractor(k=20)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    builder.fit_transform(x)\n",
    "    extractor.fit_transform(builder.tcw)\n",
    "    features = scaler.fit_transform(extractor.features_matrix)\n",
    "    \n",
    "\n",
    "    return features, y.to_numpy(), label_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6e90d-48e3-4ad5-a442-ffaa906c352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict()\n",
    "y = dict()  # Numerical labels of dataset\n",
    "labels = dict()  # Text labels of dataset\n",
    "\n",
    "x['socc'], y['socc'], labels['socc'] = preprocess(socc)\n",
    "x['socc'] = np.hstack((x['socc'], socc[['confidence']].to_numpy()))\n",
    "x['hasoc'], y['hasoc'], labels['hasoc'] = preprocess(hasoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a708c4-e54c-4e29-b2a5-8b09bd23da04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ffd41-96b2-49e5-ab91-bc1ca3f820e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['socc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d338348-3b0d-469b-a0c0-656c87932da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  # Do something I don't know.\n",
    "\n",
    "is_draw = False\n",
    "skip_step = 5\n",
    "\n",
    "def normal_train(x, y, theta, gamma):\n",
    "    accs = []\n",
    "    f1s = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    count = 0  # Counting the number of splits.\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        count += 1\n",
    "        print(f'\\n\\n=================\\nStratifiedKFold at the number {count}\\n===============\\n\\n')\n",
    "        clf = ImprovedOnlineGFMM(theta=theta, gamma=gamma, is_draw=is_draw)\n",
    "        clf.fit(x[train_index], y[train_index])\n",
    "        print(f'\\n\\n=================\\nValidatating -> {count}\\n===============\\n\\n')\n",
    "        y_pred = clf.predict(x[test_index])\n",
    "\n",
    "        accs.append(accuracy_score(y[test_index], y_pred))\n",
    "        f1s.append(f1_score(y[test_index], y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y[test_index], y_pred, average='weighted'))\n",
    "        precisions.append(precision_score(y[test_index], y_pred, average='weighted'))\n",
    "\n",
    "    return np.mean(accs), np.mean(recalls), np.mean(precisions), np.mean(f1s)\n",
    "        \n",
    "        \n",
    "\n",
    "# Predict then fit.\n",
    "# Return lists of metrics.\n",
    "def ptf_train(x, y, theta, gamma):\n",
    "    accs = dict()\n",
    "    f1s = dict()\n",
    "    recalls = dict()\n",
    "    precisions = dict()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    count = 0  # Counting the number of splits.\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        count += 1\n",
    "        print(f'\\n\\n=================\\nStratifiedKFold at the number {count}\\n===============\\n\\n')\n",
    "        source_clf = ImprovedOnlineGFMM(theta=theta, gamma=gamma, is_draw=is_draw)\n",
    "        source_clf.fit(x[train_index], y[train_index])\n",
    "        print(f'\\n\\n=================\\nValidatating -> {count}\\n===============\\n\\n')\n",
    "        n_test = len(x[test_index])\n",
    "        skip = 0\n",
    "\n",
    "        while skip < n_test:\n",
    "            y_pred = []  # Storing predicting results.\n",
    "\n",
    "            clf = copy.deepcopy(source_clf)\n",
    "            \n",
    "            print(f'\\n\\n=================\\nThe skip number of -> {skip}\\n===============\\n\\n')            \n",
    "            skipping_value = skip\n",
    "            for sample, true_predict in zip(x[test_index], y[test_index]):\n",
    "                # Store predicted result.\n",
    "                y_pred.append(clf.predict(np.atleast_2d(sample))[0])\n",
    "\n",
    "                # Check if there is a skip for not updating model.\n",
    "                if skipping_value > 0:\n",
    "                    print(f'\\n\\n=================\\nSkipping the sample {skip - skipping_value}\\n===============\\n\\n')\n",
    "                    skipping_value -= 1\n",
    "                    continue\n",
    "    \n",
    "                # Update model\n",
    "                clf.fit(np.atleast_2d(sample), np.array([true_predict]))\n",
    "    \n",
    "            y_pred = np.array(y_pred)\n",
    "\n",
    "            if skip not in recalls:\n",
    "                accs[skip] = []\n",
    "                f1s[skip] = []\n",
    "                recalls[skip] = []\n",
    "                precisions[skip] = []\n",
    "            \n",
    "            accs[skip].append(accuracy_score(y[test_index], y_pred))\n",
    "            f1s[skip].append(f1_score(y[test_index], y_pred, average='weighted'))\n",
    "            recalls[skip].append(recall_score(y[test_index], y_pred, average='weighted'))\n",
    "            precisions[skip].append(precision_score(y[test_index], y_pred, average='weighted'))\n",
    "\n",
    "            # Increment the value of skip\n",
    "            skip += skip_step\n",
    "\n",
    "        # Final test, no updates.\n",
    "        print(f'\\n\\n=================\\nThis time the model will not be updated\\n===============\\n\\n')\n",
    "        clf = ImprovedOnlineGFMM(theta=theta, gamma=gamma, is_draw=is_draw)\n",
    "        clf.fit(x[train_index], y[train_index])\n",
    "        print(f'\\n\\n=================\\nValidatating -> {count}\\n===============\\n\\n')\n",
    "\n",
    "        y_pred = clf.predict(x[test_index])\n",
    "        skip = n_test\n",
    "        \n",
    "        if skip not in recalls:\n",
    "            accs[skip] = []\n",
    "            f1s[skip] = []\n",
    "            recalls[skip] = []\n",
    "            precisions[skip] = []\n",
    "        accs[skip].append(accuracy_score(y[test_index], y_pred))\n",
    "        f1s[skip].append(f1_score(y[test_index], y_pred, average='weighted'))\n",
    "        recalls[skip].append(recall_score(y[test_index], y_pred, average='weighted'))\n",
    "        precisions[skip].append(precision_score(y[test_index], y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "    for skip in recalls:\n",
    "        accs[skip] = np.mean(accs[skip])\n",
    "        f1s[skip] = np.mean(f1s[skip])\n",
    "        recalls[skip] = np.mean(recalls[skip])\n",
    "        precisions[skip] = np.mean(precisions[skip])\n",
    "\n",
    "    return accs, recalls, precisions, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3b99f-8a88-450a-a110-1beac1680fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "gamma = 1\n",
    "\n",
    "# Dictionary to store results.\n",
    "ptf = dict()\n",
    "\n",
    "for theta in thetas:\n",
    "    ptf[theta] = {\n",
    "        'socc': {\n",
    "            'accuracy': dict(),\n",
    "            'recall': dict(),\n",
    "            'precision': dict(),\n",
    "            'f1': dict(),\n",
    "        },\n",
    "        'hasoc': {\n",
    "            'accuracy': dict(),\n",
    "            'recall': dict(),\n",
    "            'precision': dict(),\n",
    "            'f1': dict(),\n",
    "        },\n",
    "    }\n",
    "\n",
    "for theta in thetas:\n",
    "    print(f'\\n\\n=================\\nComputing result theta {theta}\\n===============\\n\\n')\n",
    "    for dataset in ptf[theta]:\n",
    "        print(f'\\n\\n=================\\nLoading dataset {dataset}...\\n===============\\n\\n')\n",
    "        acc, rec, prec, f1 = ptf_train(x[dataset], y[dataset], theta, gamma)\n",
    "        ptf[theta][dataset]['accuracy'] = acc\n",
    "        ptf[theta][dataset]['recall'] = rec\n",
    "        ptf[theta][dataset]['precision'] = prec\n",
    "        ptf[theta][dataset]['f1'] = f1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2222c59-ef0e-4a92-9c7c-a8a29ce8a025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
