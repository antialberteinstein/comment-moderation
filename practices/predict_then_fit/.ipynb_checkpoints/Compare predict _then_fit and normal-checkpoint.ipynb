{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9e4cdb-0713-4918-acfd-b67f07744afd",
   "metadata": {},
   "source": [
    "# Compare predict then fit and normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a6446-1064-4154-8045-84f4f590f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the syspath\n",
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.abspath(os.path.join('..', '..'))\n",
    "\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9fb6746-52a3-488c-a2af-edeccda02fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4dc07e-caa4-46e5-93a1-a045c80eb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_dataset(path):\n",
    "    dataset_path = os.path.join(root_path, *path.split('/'))\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "socc = retrieve_dataset('dataset/SOCC/processed/socc.csv')\n",
    "detox = retrieve_dataset('dataset/DETOX/processed/detox.csv')\n",
    "hasoc = retrieve_dataset('dataset/HASOC/processed/en_train.csv')\n",
    "\n",
    "# Disable because currently not support other Languages.\n",
    "# hasoc_de = retrieve_dataset('dataset/HASOC/processed/de_train.csv')\n",
    "# hasoc_hi = retrieve_dataset('dataset/HASOC/processed/hi_train.csv')\n",
    "\n",
    "trawling = retrieve_dataset('dataset/Trawling/processed/trawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a8e438-d2c0-4a5a-af22-4fa8ed46e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import optuna\n",
    "from hbbrain.numerical_data.incremental_learner.iol_gfmm import ImprovedOnlineGFMM\n",
    "from preprocessing.tcw_builder import TCWBuilder\n",
    "from preprocessing.svd_extractor import SVDExtractor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d21931d-d92b-47f3-b340-6ad71ac918f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    x = dataset['text']\n",
    "    labels = dataset['label']\n",
    "    # Store y as a numpy array of labels' indeces.\n",
    "    y = np.arange(len(labels))\n",
    "\n",
    "    builder = TCWBuilder()\n",
    "    extractor = SVDExtractor(k=20)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    builder.fit_transform(x)\n",
    "    extractor.fit_transform(builder.tcw)\n",
    "    features = scaler.fit_transform(extractor.features_matrix)\n",
    "    \n",
    "\n",
    "    return features, y, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b6e90d-48e3-4ad5-a442-ffaa906c352f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocc\u001b[39m\u001b[38;5;124m'\u001b[39m], y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocc\u001b[39m\u001b[38;5;124m'\u001b[39m], labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess(socc)\n\u001b[0;32m      6\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocc\u001b[39m\u001b[38;5;124m'\u001b[39m], socc[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_numpy()))\n\u001b[1;32m----> 7\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetox\u001b[39m\u001b[38;5;124m'\u001b[39m], y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetox\u001b[39m\u001b[38;5;124m'\u001b[39m], labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetox\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess(detox)\n\u001b[0;32m      8\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasoc\u001b[39m\u001b[38;5;124m'\u001b[39m], y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasoc\u001b[39m\u001b[38;5;124m'\u001b[39m], labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasoc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess(hasoc)\n\u001b[0;32m      9\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrawling\u001b[39m\u001b[38;5;124m'\u001b[39m], y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrawling\u001b[39m\u001b[38;5;124m'\u001b[39m], labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrawling\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess(trawling)\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      8\u001b[0m extractor \u001b[38;5;241m=\u001b[39m SVDExtractor(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      9\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 11\u001b[0m builder\u001b[38;5;241m.\u001b[39mfit_transform(x)\n\u001b[0;32m     12\u001b[0m extractor\u001b[38;5;241m.\u001b[39mfit_transform(builder\u001b[38;5;241m.\u001b[39mtcw)\n\u001b[0;32m     13\u001b[0m features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(extractor\u001b[38;5;241m.\u001b[39mfeatures_matrix)\n",
      "File \u001b[1;32m~\\OneDrive - The University of Technology\\Desktop\\Nguyen\\CS\\projects\\comment-moderation\\preprocessing\\tcw_builder.py:17\u001b[0m, in \u001b[0;36mTCWBuilder.fit_transform\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(x)\n",
      "File \u001b[1;32m~\\OneDrive - The University of Technology\\Desktop\\Nguyen\\CS\\projects\\comment-moderation\\preprocessing\\tcw_builder.py:30\u001b[0m, in \u001b[0;36mTCWBuilder._fit\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m     29\u001b[0m     tokenized_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize(tr)\n\u001b[1;32m---> 30\u001b[0m     stemmed_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stem(tokenized_words)\n\u001b[0;32m     31\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tf(stemmed_words)\n\u001b[0;32m     32\u001b[0m     dicts\u001b[38;5;241m.\u001b[39mappend(dct)\n",
      "File \u001b[1;32m~\\OneDrive - The University of Technology\\Desktop\\Nguyen\\CS\\projects\\comment-moderation\\preprocessing\\tcw_builder.py:61\u001b[0m, in \u001b[0;36mTCWBuilder._stem\u001b[1;34m(tokenized_words)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stem\u001b[39m(tokenized_words):\n\u001b[0;32m     60\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [stemmer\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokenized_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(word, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalpha()]\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:673\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    671\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step1a(stem)\n\u001b[0;32m    672\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step1b(stem)\n\u001b[1;32m--> 673\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step1c(stem)\n\u001b[0;32m    674\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step2(stem)\n\u001b[0;32m    675\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step3(stem)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:422\u001b[0m, in \u001b[0;36mPorterStemmer._step1c\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moriginal_condition\u001b[39m(stem):\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contains_vowel(stem)\n\u001b[1;32m--> 422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_rule_list(\n\u001b[0;32m    423\u001b[0m     word,\n\u001b[0;32m    424\u001b[0m     [\n\u001b[0;32m    425\u001b[0m         (\n\u001b[0;32m    426\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    427\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    428\u001b[0m             (\n\u001b[0;32m    429\u001b[0m                 nltk_condition\n\u001b[0;32m    430\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNLTK_EXTENSIONS\n\u001b[0;32m    431\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m original_condition\n\u001b[0;32m    432\u001b[0m             ),\n\u001b[0;32m    433\u001b[0m         )\n\u001b[0;32m    434\u001b[0m     ],\n\u001b[0;32m    435\u001b[0m )\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:268\u001b[0m, in \u001b[0;36mPorterStemmer._apply_rule_list\u001b[1;34m(self, word, rules)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mendswith(suffix):\n\u001b[0;32m    267\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_suffix(word, suffix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m condition(stem):\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m stem \u001b[38;5;241m+\u001b[39m replacement\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;66;03m# Don't try any further rules\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:417\u001b[0m, in \u001b[0;36mPorterStemmer._step1c.<locals>.nltk_condition\u001b[1;34m(stem)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnltk_condition\u001b[39m(stem):\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    This has been modified from the original Porter algorithm so\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    that y->i is only done when y is preceded by a consonant,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m    conflate with 'spied', 'tried', 'flies' ...\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stem) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consonant(stem, \u001b[38;5;28mlen\u001b[39m(stem) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:144\u001b[0m, in \u001b[0;36mPorterStemmer._is_consonant\u001b[1;34m(self, word, i)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consonant(word, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:144\u001b[0m, in \u001b[0;36mPorterStemmer._is_consonant\u001b[1;34m(self, word, i)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consonant(word, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: PorterStemmer._is_consonant at line 144 (2966 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\nltk\\stem\\porter.py:144\u001b[0m, in \u001b[0;36mPorterStemmer._is_consonant\u001b[1;34m(self, word, i)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consonant(word, i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "x = dict()\n",
    "y = dict()  # Numerical labels of dataset\n",
    "labels = dict()  # Text labels of dataset\n",
    "\n",
    "# x['socc'], y['socc'], labels['socc'] = preprocess(socc)\n",
    "# x['socc'] = np.hstack((x['socc'], socc[['confidence']].to_numpy()))\n",
    "x['detox'], y['detox'], labels['detox'] = preprocess(detox)\n",
    "# x['hasoc'], y['hasoc'], labels['hasoc'] = preprocess(hasoc)\n",
    "# x['trawling'], y['trawling'], labels['trawling'] = preprocess(trawling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a708c4-e54c-4e29-b2a5-8b09bd23da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['socc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0cf2a-1ad4-45a1-9088-acd9b4c7493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['detox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ffd41-96b2-49e5-ab91-bc1ca3f820e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['hasoc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefca5c-f807-46a3-af0f-5b5f9ac0775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['trawling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d338348-3b0d-469b-a0c0-656c87932da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
